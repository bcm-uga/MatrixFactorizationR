% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lfmm.R
\name{lfmm_lasso}
\alias{lfmm_lasso}
\title{LFMM least-squares estimates with lasso penalty}
\usage{
lfmm_lasso(Y, X, K, nozero.prop = 0.1, lambda.num = 100,
  lambda.min.ratio = 0.01, lambda = NULL, it.max = 100,
  relative.err.epsilon = 1e-06)
}
\arguments{
\item{Y}{a response variable matrix with n rows and p columns.
Each column is a response variable (e.g., SNP genotype,
gene expression level, beta-normalized methylation profile, etc).
Response variables must be encoded as numeric.}

\item{X}{an explanatory variable matrix with n rows and d columns.
Each column corresponds to a distinct explanatory variable (eg. phenotype).
Explanatory variables must be encoded as numeric.}

\item{K}{an integer for the number of latent factors in the regression model.}

\item{nozero.prop}{a numeric value for the expected proportion of non-zero effect sizes.}

\item{lambda.num}{a numeric value for the number of 'lambda' values (obscure).}

\item{lambda.min.ratio}{(obscure parameter) a numeric value for the smallest \code{lambda} value,
A fraction of \code{lambda.max}, the data derived entry value (i.e. the smallest value for
which all coefficients are zero).}

\item{lambda}{(obscure parameter) Smallest value of \code{lambda}. A fraction of 'lambda.max',
the (data derived) entry value (i.e. the smallest value for which all
coefficients are zero).}

\item{it.max}{an integer value for the number of iterations of the algorithm.}

\item{relative.err.epsilon}{a numeric value for a relative convergence error. Determine
whether the algorithm converges or not.}
}
\value{
an object of class \code{lfmm} with the following attributes:
\itemize{
\item U the latent variable score matrix with dimensions n x K.
\item V the latent variable axes matrix with dimensions p x K.
\item B the effect size matrix with dimensions p x d.
}
}
\description{
This function computes regularized least squares estimates
for the parameters of latent factor mixed models using a lasso penalty.
}
\details{
The algorithm minimizes the following penalized least-squares criterion

\deqn{ Llasso(U, V, B) =
\frac{1}{2} ||Y - U V^{T} - X B^T||_{F}^2 + \frac{\lambda}{2}
||B||^{2}_{2} , }
where Y is a response data matrix, X contains all explanatory variables,
U denotes the score matrix, V is the loading matrix, and B is the effect
size matrix.
}
\examples{
library(lfmm)
data(example.data)
Y <- scale(example.data$genotype, scale = FALSE)
X <- scale(example.data$phenotype)

## fits an lfmm model, i.e, computes B, U, V:
mod.lfmm <- lfmm_lasso(Y = Y, X = X, K = 6)

## performs association testing using the fitted model:
pv <- lfmm_test(Y = Y, X = X, lfmm = mod.lfmm, calibrate = "gif")

## Manhattan plot
plot(-log10(pv$calibrated.pvalue), pch = 19, cex = .2, col = "grey")
points(example.data$causal.set, 
      -log10(pv$calibrated.pvalue)[example.data$causal.set], 
       type = "h", col = "blue")


## Another example 
## sample data
K <- 3
dat <- lfmm_sampler(n = 100, p = 1000, K = K,
                    outlier.prop = 0.1,
                    cs = c(0.6),
                    sigma = 0.2,
                    B.sd = 1.0,
                    U.sd = 1.0,
                    V.sd = 1.0)
## run lfmm
lfmm.res <- lfmm_lasso(Y = dat$Y, X = dat$X, K = 3, nozero.prop= 0.2)

## plot size effect matrix
id <- seq_along(lfmm.res$B)
cols <- c('red', 'green')[as.numeric(id \%in\% dat$outlier) + 1]
plot(id, lfmm.res$B, col = cols)
}
\author{
cayek
}
